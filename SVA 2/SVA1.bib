@inproceedings{Pegasos,
 author = {Shalev-Shwartz, Shai and Singer, Yoram and Srebro, Nathan},
 title = {Pegasos: Primal Estimated sub-GrAdient SOlver for SVM},
 booktitle = {Proceedings of the 24th international conference on Machine learning},
 series = {ICML '07},
 year = {2007},
 isbn = {978-1-59593-793-3},
 location = {Corvalis, Oregon},
 pages = {807--814},
 numpages = {8},
 url = {http://doi.acm.org/10.1145/1273496.1273598},
 doi = {10.1145/1273496.1273598},
 acmid = {1273598},
 publisher = {ACM},
 address = {New York, NY, USA},
} 
@article{Norma,
  added-at = {2012-01-30T00:00:00.000+0100},
  author = {Kivinen, Jyrki and Smola, Alexander J. and Williamson, Robert C.},
  biburl = {http://www.bibsonomy.org/bibtex/23ea2ea4c4d24b4efc689e2afc576828f/dblp},
  ee = {http://dx.doi.org/10.1109/TSP.2004.830991},
  interhash = {3d6c99c21bae8186d94af3bc02d92302},
  intrahash = {3ea2ea4c4d24b4efc689e2afc576828f},
  journal = {IEEE Transactions on Signal Processing},
  keywords = {dblp},
  number = 8,
  pages = {2165-2176},
  timestamp = {2012-01-30T00:00:00.000+0100},
  title = {Online learning with kernels.},
  url = {http://dblp.uni-trier.de/db/journals/tsp/tsp52.html#KivinenSW04},
  volume = 52,
  year = 2004
}
@TECHREPORT{Boostsvm,
    author = {Gunnar Ratsch and Bernhard Scholkopf and Sebastian Mika and Klaus-Robert Muller},
    title = {SVM and boosting: One class},
    institution = {},
    year = {2000}
}
@inproceedings{OnlineBoost,
 author = {H. Grabner, M. Grabner, and H. Bischof},
 title = {Real-time Tracking via On-line Boosting},
 booktitle = {Proceedings British Machine Vision Conference (BMVC), volume 1},
 year = {2006},
 location = {Corvalis, Oregon},
 pages = {47-56},
 numpages = {10},
} 

@article{AdaBoost,
 author = {Freund, Yoav and Schapire, Robert E.},
 title = {A decision-theoretic generalization of on-line learning and an application to boosting},
 journal = {J. Comput. Syst. Sci.},
 issue_date = {Aug. 1997},
 volume = {55},
 number = {1},
 month = aug,
 year = {1997},
 issn = {0022-0000},
 pages = {119--139},
 numpages = {21},
 url = {http://dx.doi.org/10.1006/jcss.1997.1504},
 doi = {10.1006/jcss.1997.1504},
 acmid = {261549},
 publisher = {Academic Press, Inc.},
 address = {Orlando, FL, USA},
} 
@inproceedings{OZ,
    abstract = {{Bagging and boosting are well-known ensemble learning methods. They combine multiple learned base models with the aim of improving generalization performance. To date, they have been used primarily in batch mode, and no effective online versions have been proposed. We present simple online bagging and boosting algorithms that we claim perform as well as their batch counterparts.}},
    author = {Oza, N. and Russell, S.},
    booktitle = {Artificial Intelligence and Statistics 2001},
    citeulike-article-id = {2407837},
    citeulike-linkout-0 = {http://citeseerx.ist.psu.edu/viewdoc/summary?doi=10.1.1.32.8889},
    keywords = {misc},
    pages = {105--112},
    posted-at = {2008-02-21 15:26:20},
    priority = {0},
    publisher = {Morgan Kaufmann},
    title = {{Online bagging and boosting}},
    url = {http://citeseerx.ist.psu.edu/viewdoc/summary?doi=10.1.1.32.8889},
    year = {2001}
}
@book{Vapnik,
  added-at = {2011-04-06T15:00:29.000+0200},
  address = {New York, NY, USA},
  author = {Vapnik, Vladimir N.},
  biburl = {http://www.bibsonomy.org/bibtex/247ebbab65bd999205dbe30b610ff96d8/utahell},
  description = {final},
  interhash = {98898576dfede7a15fcbf60cad98f9c0},
  intrahash = {47ebbab65bd999205dbe30b610ff96d8},
  isbn = {0-387-94559-8},
  keywords = {learning svm},
  publisher = {Springer New York Inc.},
  timestamp = {2011-04-06T15:00:29.000+0200},
  title = {The Nature of Statistical Learning Theory},
  year = 1995
}
@book{IP,
 author = {Boyd, Stephen and Vandenberghe, Lieven},
 title = {Convex Optimization},
 year = {2004},
 isbn = {0521833787},
 publisher = {Cambridge University Press},
 address = {New York, NY, USA},
} 
@article{SVM,
 author = {Cortes, Corinna and Vapnik, Vladimir},
 title = {Support-Vector Networks},
 journal = {Mach. Learn.},
 issue_date = {Sept. 1995},
 volume = {20},
 number = {3},
 month = sep,
 year = {1995},
 issn = {0885-6125},
 pages = {273--297},
 numpages = {25},
 url = {http://dx.doi.org/10.1023/A:1022627411411},
 doi = {10.1023/A:1022627411411},
 acmid = {218929},
 publisher = {Kluwer Academic Publishers},
 address = {Hingham, MA, USA},
 keywords = {efficient learning algorithms, neural networks, pattern recognition, polynomial classifiers, radial basis function classifiers},
} 

@incollection{SMO,
 author = {Platt, John C.},
 chapter = {Fast training of support vector machines using sequential minimal optimization},
 title = {Advances in kernel methods},
 editor = {Sch\"{o}lkopf, Bernhard and Burges, Christopher J. C. and Smola, Alexander J.},
 year = {1999},
 isbn = {0-262-19416-3},
 pages = {185--208},
 numpages = {24},
 url = {http://dl.acm.org/citation.cfm?id=299094.299105},
 acmid = {299105},
 publisher = {MIT Press},
 address = {Cambridge, MA, USA},
}
@article{AdaAn,
    abstract = {{One of the surprising recurring phenomena observed in experiments with boosting is that the test error of the generated classifier usually does not increase as its size becomes very large, and often is observed to decrease even after the training error reaches zero. In this paper, we show that this phenomenon is related to the distribution of margins of the training examples with respect to the generated voting classification rule, where the margin of an example is simply the difference between the number of correct votes and the maximum number of votes received by any incorrect label. We show that techniques used in the analysis of Vapnik's support vector classifiers and of neural networks with small weights can be applied to voting methods to relate the margin distribution to the test error. We also show theoretically and experimentally that boosting is especially effective at increasing the margins of the training examples. Finally, we compare our explanation to those based on the bias-variance decomposition.}},
    author = {Schapire, Robert E. and Freund, Yoav and Bartlett, Peter and Lee, Wee S.},
    citeulike-article-id = {1727859},
    citeulike-linkout-0 = {http://dx.doi.org/10.2307/120016},
    citeulike-linkout-1 = {http://www.jstor.org/stable/120016},
    doi = {10.2307/120016},
    issn = {00905364},
    journal = {The Annals of Statistics},
    number = {5},
    pages = {1651--1686},
    posted-at = {2008-09-03 02:56:02},
    priority = {2},
    publisher = {Institute of Mathematical Statistics},
    title = {{Boosting the Margin: A New Explanation for the Effectiveness of Voting Methods}},
    url = {http://dx.doi.org/10.2307/120016},
    volume = {26},
    year = {1998}
}
@article{Forest,
    abstract = {{This study compared two alternative techniques for predicting forest cover types from cartographic variables. The study evaluated four wilderness areas in the Roosevelt National Forest, located in the Front Range of northern Colorado. Cover type data came from US Forest Service inventory information, while the cartographic variables used to predict cover type consisted of elevation, aspect, and other information derived from standard digital spatial data processed in a geographic information system (GIS). The results of the comparison indicated that a feedforward artificial neural network model more accurately predicted forest cover type than did a traditional statistical model based on Gaussian discriminant analysis.}},
    author = {Blackard, J.},
    citeulike-article-id = {3871976},
    citeulike-linkout-0 = {http://dx.doi.org/10.1016/S0168-1699(99)00046-0},
    doi = {10.1016/S0168-1699(99)00046-0},
    issn = {01681699},
    journal = {Computers and Electronics in Agriculture},
    month = dec,
    number = {3},
    pages = {131--151},
    posted-at = {2009-01-09 16:41:55},
    priority = {2},
    title = {{Comparative accuracies of artificial neural networks and discriminant analysis in predicting forest cover types from cartographic variables}},
    url = {http://dx.doi.org/10.1016/S0168-1699(99)00046-0},
    volume = {24},
    year = {1999}
}
